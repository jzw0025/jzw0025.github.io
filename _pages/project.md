---
title:  ""
layout: publications
permalink: /Project/
author_profile: true
comments: false
geometry: margin=1in
fontfamily: mathpazo
fontsize: 8pt
spacing: single
---

<figure>
<img src="https://raw.githubusercontent.com/jzw0025/jzw0025.github.io/main/_imgs/real_time_measurement.gif" width=500 height=500 alt="Image 1">
<figcaption> <b>Real-time</b> Objects Depth and Distance <b>Tracking and Measurement</b> in <b>3D Geomtry</b>: this project applies Intel Realsense 3D Cameras to acquire <b>RGBD imaging data</b> and to process the <b>Point Cloud Data</b> with <b>OpenGL Graphics Library</b> to visualize the real-time information with <b>Users' inputs/interactions</b>. </figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/jzw0025/jzw0025.github.io/main/_imgs/stereo_medical_image.gif" width=500 height=500 alt="Image 1">
<figcaption> <b>3D Visualization</b> of <b>volumetric image</b> with <b>stereo vision OpenGL</b> render. It uses the stereo-vision algorithm for the <b>3D OCT reconstruction</b> images of Lamina Cribrosa tissue on the back of the eye. Note: this <b>Anaglyph 3D video</b> can be viewed on the website through a pair of red&cyan glasses.</figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/jzw0025/jzw0025.github.io/main/_imgs/stereo_demo1.gif" width=500 height=500 alt="Image 1">
<figcaption> <b>3D Stereo-vision Visualization</b>(i.e. Google Cardboard with the cellphone screen). The <b>3D(RGBD) camera</b> outputs were processed and rendered in real-time with <b>OpenGL</b> library, in which <b>left eye</b> and <b>right eye</b> information were processed and <b>synchronized</b> in two different <b>frustrums and projections</b>. This also can be applied with the tracking and measurement project to get human inputs/interactions in real-time. </figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/jzw0025/jzw0025.github.io/main/_imgs/stereo_demo2.gif" width=500 height=500 alt="Image 1">
<figcaption> <b>3D Stereo-vision Visualization</b>(i.e. Google Cardboard with the cellphone screen). The near-far objects are created with texture binding on the squares geometry, and its translations and rotations are visually tested in real-time with the stereo glasses in the <b>OpenGL</b> environment.</figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/jzw0025/jzw0025.github.io/main/_imgs/face_antispoofing_blur.gif" width=500 height=500 alt="Image 1">
<figcaption> <b>Real-time</b> face <b>anti-spoofing</b> approach for <b>surveillance camera</b> security applitions: it applies <b>foreground and geometry-based algorithms</b> with <b>Face Detection engine</b> to achieve <b>>60FPS</b> real-time speed performance. <b>Note:</b> the algorithm has been patented in the <b>U.S. 11,354,940 B2</b></figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/jzw0025/jzw0025.github.io/main/_imgs/robo_demo1.gif" width=500 height=500 alt="Image 1">
<figcaption> <b>Robotic Vision Project:</b> The design of <b>Robotic and Machine Vision</b> System for Objects <b>Detection, Segmentation, Localization, and Transferring</b>, the individual bolt can be detected and then picked up by the robotic arm giving the accurate location and pinpoint touch in the <b>3D Coordinates X-Y-Z </b> for picking. The projects use the open source the <b>"EEZYbotARM"</b> arm design with <b>Intel realsense 415</b> 3D camera and <b>Fast-RCNN model</b> for training the vision network. </figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/jzw0025/jzw0025.github.io/main/_imgs/meter.gif" width=500 height=500 alt="Image 1">
<figcaption> <b>Real-time spotting-OCR method</b> for meter digits detection and recognition: it utilizes <b>DETR(Detection Transformer Network)</b> for digits object bounding box detection and recognition. </figcaption>
</figure>



